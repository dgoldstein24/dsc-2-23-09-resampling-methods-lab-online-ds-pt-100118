{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Methods - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you have some preliminary background on bootstrapping, jacknife and permutation tests, its time to practice those skills by coding them into functions. You'll then apply these tests to a hypothesis test and compare the results to a parametric t-test.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Understand permutation testing\n",
    "* Understand what jacknife is\n",
    "* Understand what bootstrapping is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Write a function that takes a sample and generates n additional samples of the same size using bootstrapping. (Recall that bootstrapping creates additional sets by sampling with replacement.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(sample, n_additional_samples):\n",
    "    new_samples = []\n",
    "    counter = 0\n",
    "    while counter < n_additional_samples:\n",
    "        new_samples.append(np.random.choice(sample, size = len(sample), replace = True))\n",
    "        counter += 1\n",
    "    return new_samples                   \n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacknife \n",
    "\n",
    "Write a function that creates additional samples by removing one element at a time. The function should do this for each of the n items in the original sample, returning n samples, each with n-1 members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jack1(sample):\n",
    "    \"\"\"This function should take in a list of n observations and return n lists\n",
    "    each with one member (presumably the nth) removed.\"\"\"\n",
    "    # Your code here\n",
    "    new_samples = []\n",
    "    new_sample = sample\n",
    "    new_sample.pop()\n",
    "    while len(new_sample) > 0:\n",
    "        new_samples.append(new_sample)\n",
    "        new_sample.pop()\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing\n",
    "\n",
    "Define a function that generate all possible, equally sized, two set splits of two sets A and B. Sets A and B need not be the same size, but all of the generate two set splits should be of equal size. For example, if we had a set with 5 members and a set with 7 members, the function would return all possible 5-7 splits of the 12 items. \n",
    "\n",
    "\n",
    "Here's a more in depth example:  \n",
    "```A = [1,2,2]\n",
    "B = [1,3]\n",
    "permT(A, B) = [\n",
    "                ([1,2,2], [1,3]),\n",
    "                ([1,2,3], [1,2]),\n",
    "                ([1,2,1], [2,3])\n",
    "                ([1,1,3], [2,2]),\n",
    "                ([2,2,3], [1,1])\n",
    "              ]```  \n",
    "These are all the possible 3-2 member splits of the 5 elements : 1,1,2,2,3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permT(a,b):\n",
    "    size_1 = len(a)\n",
    "    size_2 = len(b)\n",
    "    items = a + b\n",
    "    copy = items\n",
    "    new_a = []\n",
    "    new_b = list(set(combinations(items, len(b))))\n",
    "    for index in range(len(new_b)):\n",
    "        new_b[index] = list(np.sort(new_b[index]))\n",
    "    for item in new_b:\n",
    "        count = 0\n",
    "        for i in range(len(new_b)):\n",
    "            if item == new_b[i]:\n",
    "                count += 1\n",
    "        if count > 1:\n",
    "            new_b.remove(item)       \n",
    "    #new_b is completed\n",
    "    \n",
    "    for item in new_b:\n",
    "        copy_new = a + b\n",
    "        for i in range(len(item)):\n",
    "            x = item[i]\n",
    "            copy_new.remove(x)\n",
    "        new_a.append(copy_new)\n",
    "    \n",
    "    new = []\n",
    "    for i in range(len(new_b)):\n",
    "        permutation = (new_a[i], new_b[i])\n",
    "        new.append(permutation)\n",
    "    return new\n",
    "    \n",
    "    \n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([2, 2, 1], [1, 3]),\n",
       " ([2, 1, 3], [1, 2]),\n",
       " ([1, 2, 1], [2, 3]),\n",
       " ([1, 1, 3], [2, 2]),\n",
       " ([2, 2, 3], [1, 1])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [1,2,2]\n",
    "B = [1,3]\n",
    "permT(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Testing in Practice\n",
    "Let's further investigate the scenario proposed in the previous lesson. Below are two samples A and B. The samples are mock data for the blood pressure of sample patients. The research study is looking to validate whether there is a statistical difference in the blood pressure of these two groups using a 5% signifincance level.  First, calculate the mean blood pressure of each of the two samples. Then, calculate the difference of these means. From there, use your `permT()` function, defined above, to generate all the possible combinations of the entrie sample data into A-B splits of equivalent sizes as the original sets. For each of these combinations, calculate the mean blood pressure of the two groups and record the difference between these sample means. The full collection of the difference in means between these generated samples will serve as the denominator to calculate the p-value associated with the difference between the original sample means.\n",
    "\n",
    "For example, in our small handwritten example above:\n",
    "\n",
    "$\\mu_a = \\frac{1+2+2}{3} = \\frac{5}{3}$  \n",
    "and  \n",
    "$\\mu_b = \\frac{1+3}{2} = \\frac{4}{2} = 2$  \n",
    "\n",
    "Giving us\n",
    "\n",
    "$\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$\n",
    "\n",
    "In comparison, for our various combinations we have:\n",
    "\n",
    "([1,2,2], [1,3]):  $\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$  \n",
    "([1,2,3], [1,2]):  $\\mu_a - \\mu_b = 2 - \\frac{3}{2} = \\frac{1}{2}$  \n",
    "([1,2,1], [2,3]):  $\\mu_a - \\mu_b = \\frac{4}{3} - \\frac{5}{3} = -\\frac{1}{2}$  \n",
    "([1,1,3], [2,2]):  $\\mu_a - \\mu_b = \\frac{5}{3} - 2 = \\frac{1}{2}$  \n",
    "([2,2,3], [1,1]):  $\\mu_a - \\mu_b = \\frac{7}{3} - 1 = \\frac{4}{3}$  \n",
    "\n",
    "A standard hypothesis test for this scenario might be:\n",
    "\n",
    "$h_0: \\mu_a = \\mu_b$  \n",
    "$h_1: \\mu_a < \\mu_b$  \n",
    "  \n",
    "Thus comparing our sample difference to the differences of our possible combinations, we look at the number of experiments from our permutation space that were the same or greater then our sample statistic, divided by the total number of permutations. In this case, 4 out of 5 of the permutation cases produced the same or greater differences in the two sample means. This value .8 is a strong indication that we cannot refute the null hypothesis for this instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reject null hypothesis\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "a = A\n",
    "b = B\n",
    "sample_mean_difference= np.array(a).mean() - np.array(b).mean()\n",
    "matrix = permT(a,b)\n",
    "mean_differences = []\n",
    "for item in matrix:\n",
    "    first = np.array(item[0])\n",
    "    second = np.array(item[1])\n",
    "    first_mean = first.mean()\n",
    "    second_mean = second.mean()\n",
    "    diff = first_mean - second_mean\n",
    "    mean_differences.append(diff)\n",
    "mean_differences = np.array(mean_differences)\n",
    "count = 0\n",
    "for value in mean_differences:\n",
    "    if sample_mean_difference < value:\n",
    "        count += 1\n",
    "p = count / len(mean_differences)\n",
    "a_val = .05\n",
    "if p > a_val:\n",
    "    print ('cannot reject null hypothesis')\n",
    "    print(p)\n",
    "else:\n",
    "    print('null hypothesis rejected')\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-test Revisited\n",
    "\n",
    "The parameteric statistical test equivalent to our permutation test above would be a t-test of the two groups. Perform a t-test on the same data above in order to calculate the p-value. How does this compare to the above results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7576767609436587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6827060250409898"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = A\n",
    "b = B\n",
    "mean_difference = sample_mean_difference\n",
    "n_a = len(a)\n",
    "n_b = len(b)\n",
    "s_a = np.var(a)\n",
    "s_b = np.var(b)\n",
    "denom = np.sqrt((s_a / n_a) + (s_b / n_b))\n",
    "print(denom)\n",
    "t = mean_difference  / denom\n",
    "p = stats.t.sf(np.abs(t), n_a + n_b - 1) * 2\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Applied\n",
    "\n",
    "Use your code above to apply the bootstrap technique to this hypothesis testing scenario. In other words, similar to the permutation testing you performed above, compute additional samples (arbitrarily let's say 1000) of the same size as the original sample, with replacement. For each of these additional samples, compute whether the difference in sample means is the same or greater then that of the original samples. Use this to calculate an overall p-value for the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "count = 0\n",
    "n_additional_samples = 1000\n",
    "for i in range(n_additional_samples):\n",
    "    new_a = bootstrap(a, len(a))\n",
    "    new_b = bootstrap(b, len(b))\n",
    "    new_diff = np.mean(new_a) - np.mean(new_b)\n",
    "    if new_diff >= mean_difference:\n",
    "        count += 1\n",
    "p = count / n_additional_samples\n",
    "p\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab you practice coding modern statistical resampling techniques of the 20th century! You also started to compare these non-parametric methods to other parametric methods such as the t-test that we previously discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
